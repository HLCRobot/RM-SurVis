

@ARTICLE{4468719,
  abstract = {Robotic mapping is the process of automatically constructing an environment representation using mobile robots. We address the problem of semantic mapping, which consists of using mobile robots to create maps that represent not only metric occupancy but also other properties of the environment. Specifically, we develop techniques to build maps that represent activity and navigability of the environment. Our approach to semantic mapping is to combine machine learning techniques with standard mapping algorithms. Supervised learning methods are used to automatically associate properties of space to the desired classification patterns. We present two methods, the first based on hidden Markov models and the second on support vector machines. Both approaches have been tested and experimentally validated in two problem domains: terrain mapping and activity-based mapping.},
  author={Wolf, Denis F. and Sukhatme, Gaurav S.},
  journal={IEEE Transactions on Robotics}, 
  title={Semantic Mapping Using Mobile Robots}, 
  year={2008},
  volume={24},
  number={2},
  pages={245-258},
  publisher = {IEEE},
  series={TRO},
  url = {https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=4468719},
  keywords={type:Mobile robots, Terrain mapping, Robotics and automation, Machine learning, Machine learning algorithms, Supervised learning, Hidden Markov models, Support vector machines, Support vector machine classification, Testing, Activity monitoring, robot mapping, semantic mapping, supervised learning, terrain mapping, Activity monitoring, robot mapping, semantic mapping, supervised learning, terrain mapping},
  doi={10.1109/TRO.2008.917001}}

@ARTICLE{9708724,
  abstract = {In this article, we address a multi-robot planning problem in environments with partially unknown semantics. The environment is assumed to have a known geometric structure (e.g., walls) and to be occupied by static labeled landmarks with uncertain positions and classes. This modeling approach gives rise to an uncertain semantic map generated by semantic simultaneous localization and mapping algorithms. Our goal is to design control policies for robots equipped with noisy perception systems so that they can accomplish collaborative tasks captured by global temporal logic specifications. To specify missions that account for environmental and perceptual uncertainty, we employ a fragment of linear temporal logic (LTL), called co-safe LTL, defined over perception-based atomic predicates modeling probabilistic satisfaction requirements. The perception-based LTL planning problem gives rise to an optimal control problem, solved by a novel sampling-based algorithm, that generates open-loop control policies that are updated online to adapt to a continuously learned semantic map. We provide extensive experiments to demonstrate the efficiency of the proposed planning architecture.},
  author={Kantaros, Yiannis and Kalluraya, Samarth and Jin, Qi and Pappas, George J.},
  journal={IEEE Transactions on Robotics}, 
  title={Perception-Based Temporal Logic Planning in Uncertain Semantic Maps}, 
  year={2022},
  volume={38},
  number={4},
  pages={2536-2556},
  publisher = {IEEE},
  series={TRO}
  url = {https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9708724},
  keywords={type:Semantics, Robots;Robot sensing systems, Planning, Uncertainty, Task analysis, Sensors, Motion planning, multi-robot systems, sensor-based and reactive planning},
  doi={10.1109/TRO.2022.3144073}}

@ARTICLE{10824916,
  abstract = {Representing the 3-D environment with instance-aware semantic and geometric information is crucial for interaction-aware robots in dynamic environments. Nevertheless, creating such a representation poses challenges due to sensor noise, instance segmentation and tracking errors, and the objects' dynamic motion. This article introduces a novel particle-based instance-aware semantic occupancy map to tackle these challenges. Particles with an augmented instance state are used to estimate the probability hypothesis density (PHD) of the objects and implicitly model the environment. Utilizing a state-augmented sequential Monte Carlo PHD filter, these particles are updated to jointly estimate occupancy status, semantic, and instance IDs, mitigating noise. In addition, a memory module is adopted to enhance the map's responsiveness to previously observed objects. Experimental results on the Virtual KITTI 2 dataset demonstrate that the proposed approach surpasses state-of-the-art methods across multiple metrics under different noise conditions. Subsequent tests using real-world data further validate the effectiveness of the proposed approach.},
  author={Chen, Gang and Wang, Zhaoying and Dong, Wei and Alonso-Mora, Javier},
  journal={IEEE Transactions on Robotics}, 
  title={Particle-Based Instance-Aware Semantic Occupancy Mapping in Dynamic Environments}, 
  year={2025},
  volume={41},
  number={},
  pages={1155-1171},
  publisher = {IEEE},
  series={TRO},
  url = {https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10824916},
  keywords={type:Semantics, Noise, Dynamics, Radio frequency, Robots, Robot sensing systems, Particle measurements, Memory modules, Finite element analysis, Europe, Dynamic environment representation, mapping, semantic scene understanding},
  doi={10.1109/TRO.2025.3526084}}

@INPROCEEDINGS{6145946,
  abstract = {We describe hybrid semantic mapping method with classified area information for home environments. The hybrid map contains two map types: a grid map, and a classified area information-in-grid (CAIG) map. The grid and CAIG maps can be used for intelligent navigation (e.g., localization and path planning) and motion selection, respectively. In home environments, a door can be used to divide an area into various sections such as a room or a kitchen. Therefore, we use a grid map of the home environment and door information as main clues to classify the area and to build the hybrid map. The proposed method is verified by various experiments. We show that the robot can build a hybrid semantic map autonomously in home environments.},
  author={Joong-Tae Park and Song, Jae-Bok},
  booktitle={2011 8th International Conference on Ubiquitous Robots and Ambient Intelligence (URAI)}, 
  title={Hybrid semantic mapping using door information}, 
  year={2011},
  volume={},
  number={},
  pages={128-130},
  publisher = {IEEE},
  series={URAI},
  url = {https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=6145946},
  keywords={type:Semantics, Robot kinematics, Robot sensing systems, Mobile robots, Buildings, Classification algorithms, Area classification, semantic map, hybrid map, grid map, mobile robot},
  doi={10.1109/URAI.2011.6145946}}

@INPROCEEDINGS{6462988,
  abstract = {We propose a semantic map representation and human-like navigation strategies for the mobile robot with a monocular camera. First, we develop a method to automatically detect landmarks, which make up a perceived planar region. Next, we build a vision-based map with the detected visual planar landmarks. To build a map with a single camera, we use the concept of bearing-SLAM. The landmark bearings are measured by a camera from the detected planar regions. By measuring two bearings between three feature points in the detected planar regions, we estimate the distance from the robot to the landmark for an observation model. After building a vision-based map, we extract semantic information. The proposed semantic map represents the topology of the environment with nodes (area and landmarks) and their spatial relationships. Next, we attempt to apply human navigation strategies for the robot navigation with semantic map. We apply strategies (path integration, view-dependent place recognition, reorientation, and active searching for additional landmarks) to mobile robots and demonstrate a human-like navigation system based on a semantic map.},
  author={Dong Wook Ko and Yi, Chuho and Suh, Il Hong},
  booktitle={2012 9th International Conference on Ubiquitous Robots and Ambient Intelligence (URAI)}, 
  title={Semantic mapping and navigation with visual planar landmarks}, 
  year={2012},
  volume={},
  number={},
  pages={255-258},
  publisher = {IEEE},
  series={URAI},
  url = {https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=6462988},
  keywords={type:Semantics, Navigation, Visualization, Cameras, Robot vision systems, Mobile robots, Semantic map, Navigation, SLAM, spatial relationship, Planar},
  doi={10.1109/URAI.2012.6462988}}

@INPROCEEDINGS{10034105,
  abstract = {If a robot uses static semantic maps to search targets in dynamic environments, its performance will be unsatisfactory. To solve this problem, a lightweight environment construction method for robot target search tasks is proposed. This novel semantic map can be updated automatically in a dynamic environment, in which unsupervised region division methods are used to establish the attribution of targets to subregions of the environment. Then, a target search strategy is designed to optimize the expected time. Experimental results demonstrated that this semantic map has an excellent real-time and adaptive ability. It does not need a lot of computing resources and storage like 3D point cloud semantic map. It is also convenient for the robot to update automatically online.},
  author={Li, Dong and Zhang, Botao and Wu, Qiuxuan and She, Qingshan and Zhong, Chaoliang},
  booktitle={2022 34th Chinese Control and Decision Conference (CCDC)}, 
  title={A Lightweight Semantic Map Construction Method for Robot Target Search}, 
  year={2022},
  volume={},
  number={},
  pages={3560-3564},
  publisher = {IEEE},
  series={CCDC},
  url = {https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10034105},
  keywords={type:Point cloud compression, Three-dimensional displays, Computational modeling, Semantics, Robot sensing systems, Search problems, Real-time systems, Mobile robot, Semantic map, Region division, Target search},
  doi={10.1109/CCDC55256.2022.10034105}}

@INPROCEEDINGS{9832075,
  abstract = {With the rapid development of artificial intelligence technology, indoor mobile robots are widely applied in human's daily life. Traditional SLAM-based methods mostly rely on low-level geometric features, such as points, lines, etc., which cannot achieve human-robot interaction and intelligent decision-making. In this paper, we propose an object-augmented semantic mapping method, which exploits the technique of object detection and Joint calibration to construct the object semantics of indoor environments. In order to improve the mapping accuracy for robots, we perform the data association for maintaining the temporal consistency of semantic representations. Experimental results indicate that the proposed object-augmented semantic mapping system exhibits great performance in the accuracy of semantic mapping.},
  author={Song, Xu and Liang, Xuan and Zhijiang, Zuo and Huaidong, Zhou},
  booktitle={2022 IEEE 2nd International Conference on Software Engineering and Artificial Intelligence (SEAI)}, 
  title={A Object-augmented Semantic Mapping System for Indoor Mobile Robots}, 
  year={2022},
  volume={},
  number={},
  pages={225-229},
  publisher = {IEEE},
  series={SEAI},
  url = {https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9832075},
  keywords={type:Semantics, Decision making, Human-robot interaction, Object detection, Indoor environment, Calibration, Mobile robots, indoor mobile robots, semantic mapping, data association},
  doi={10.1109/SEAI55746.2022.9832075}}

@INPROCEEDINGS{8785776,
  abstract = {This paper proposes a method to build a semantic map for robot navigation by using a laser sensor and monocular vision. Laser data is used to construct an environmental grid map, which can guide the robot forward without collision. In this paper, we assume the indoor environment is one of the floors of the building. By using the monocular vision, the mobile robot can automatically search the doorplate of each office room and recognize the room number, which is used as an environmental semantic identifier. We assign the semantic label to the grid map so that the constructed map includes not only the spatial information but also the semantic information. The robot traverses the target floor and completes the construction of the semantic map automatically. The experimental result has shown the robot can be navigated to any given address in the target floor to complete the visit task by using our proposed semantic map.},
  author={Liang, Jing and Song, Wei and Shen, Linyong and Zhang, Yanan},
  booktitle={2019 IEEE 8th Joint International Information Technology and Artificial Intelligence Conference (ITAIC)}, 
  title={Indoor Semantic Map Building for Robot Navigation}, 
  year={2019},
  volume={},
  number={},
  pages={794-798},
  series={ITAIC},
  publisher = {IEEE},
  url = {https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8785776},
  keywords={type:Navigation, Semantics, Robot kinematics, Robot sensing systems, Lasers, Image segmentation, semantic map, autonomous navigation, doorplate number, laser sensor, monocular vision.},
  doi={10.1109/ITAIC.2019.8785776}}

@INPROCEEDINGS{5961919,
  abstract={We propose a novel semantic map representation method of indoor environment for mobile robots. The semantics is based on objects, which can be a desk, a wall, a room, or other things. The environment model is composed of object identifiers, object properties and relationships among them. The map is represented by Web Ontology Language (OWL) to share semantic knowledge with human. In order to extract the semantic information, plane extraction, object recognition and region inference are implemented by using the stereo image data. The experiment of representing an indoor scene shows that the method is feasible and effective to describe indoor environment.},
  author={Wang, Tingqi and Chen, Qijun},
  booktitle={Proceedings 2011 International Conference on System Science and Engineering}, 
  title={Object semantic map representation for indoor mobile robots}, 
  year={2011},
  volume={},
  number={},
  pages={309-313},
  series={ICSSE},
  publisher = {IEEE},
  url={https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=5961919},
  keywords={type:Semantics, Mobile robots, OWL, Indoor environments, Data mining, Conferences, object semantics, map representation, mobile robot},
  doi={10.1109/ICSSE.2011.5961919}}

@INPROCEEDINGS{10241093,
  abstract={Focusing on the poor real-time performance of 3D semantic mapping using RGB-D cameras in indoor environments, this paper investigates the Real-time Dense 3D Semantic Mapping (RD3DSM) using RGB-D camera. Firstly, a lightweight semantic point cloud acquisition algorithm based on keyframe is designed, which is used to segment scene images and obtain the semantic point cloud real-timely. Secondly, to address the loss of inter-frame tracking in the semantic mapping process, ORB-SLAM3 system is employed as the underlying architecture of the visual 3D semantic mapping system to provide stable camera pose. Thirdly, an information fusion mechanism of the visual 3D semantic mapping system is designed, and the OctoMap 3D scene reconstruction module is adopted to implement dense 3D map representation with semantic information, and then a visual 3D semantic mapping algorithm based on ORB-SLAM3 is proposed. Finally, the designed RD3DSM system is integrated into a robot platform. The tests were conducted on the TUM dataset and natural indoor scenes. The results show the effectiveness and real-time performance of the RD3DSM system.},
  author={Yang, Guanci and Wang, Xiaoyuan and Zhu, Dongying and Li, Yang},
  booktitle={2023 42nd Chinese Control Conference (CCC)}, 
  title={Real-time Dense 3D Semantic Mapping Using RGB-D Camera}, 
  year={2023},
  volume={},
  number={},
  pages={4419-4424},
  series={CCC},
  publisher = {IEEE},
  url={https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10241093},
  keywords={type:Point cloud compression, Visualization, Three-dimensional displays, Semantic segmentation, Semantics, Robot vision systems, Cameras, semantic segmentation, dense semantic map, visual SLAM, social robot},
  doi={10.23919/CCC58697.2023.10241093}}
